{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f715c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import time\n",
    "\n",
    "from torchrl.envs import GymEnv, StepCounter, TransformedEnv\n",
    "\n",
    "env = TransformedEnv(GymEnv(\"CartPole-v1\"), StepCounter())\n",
    "env.set_seed(0)\n",
    "\n",
    "from tensordict.nn import TensorDictModule as Mod, TensorDictSequential as Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb865b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dessign the Policy\n",
    "\n",
    "from torchrl.modules import EGreedyModule, MLP, QValueModule\n",
    "\n",
    "value_mlp = MLP(out_features=env.action_spec.shape[-1], num_cells=[64, 64])\n",
    "value_net = Mod(value_mlp, in_keys=[\"observation\"], out_keys=[\"action_value\"])\n",
    "policy = Seq(value_net, QValueModule(spec=env.action_spec))\n",
    "\n",
    "exploration_module = EGreedyModule(\n",
    "    env.action_spec, annealing_num_steps=100_000, eps_init=0.5, eps_end=0.01\n",
    ")\n",
    "\n",
    "policy_explore = Seq(policy, exploration_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df18eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
    "\n",
    "init_rand_steps = 5000\n",
    "frames_per_batch = 100\n",
    "optim_steps = 10\n",
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy_explore,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=-1,\n",
    "    init_random_frames=init_rand_steps,\n",
    ")\n",
    "rb = ReplayBuffer(storage=LazyTensorStorage(100_000))\n",
    "\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb26420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.objectives import DQNLoss, SoftUpdate\n",
    "\n",
    "loss = DQNLoss(value_network=policy, action_space=env.action_spec, delay_value=True)\n",
    "optim = Adam(loss.parameters(), lr=0.02)\n",
    "updater = SoftUpdate(loss, eps=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4b5245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 12:00:23,215 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,218 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,221 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,223 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,226 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,230 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,233 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,236 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,238 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,241 [torchrl][INFO] Max num steps: 100, rb length 5100\n",
      "2025-09-26 12:00:23,840 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:23,843 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:23,846 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:23,848 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:23,850 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:23,853 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:23,857 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:23,859 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:23,862 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:23,864 [torchrl][INFO] Max num steps: 133, rb length 6100\n",
      "2025-09-26 12:00:24,474 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:24,477 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:24,480 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:24,482 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:24,485 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:24,489 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:24,492 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:24,494 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:24,497 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:24,499 [torchrl][INFO] Max num steps: 133, rb length 7100\n",
      "2025-09-26 12:00:25,291 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:25,294 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:25,297 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:25,300 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:25,303 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:25,306 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:25,309 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:25,311 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:25,314 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:25,317 [torchrl][INFO] Max num steps: 194, rb length 8100\n",
      "2025-09-26 12:00:26,030 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,033 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,036 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,038 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,041 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,044 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,046 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,048 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,051 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,054 [torchrl][INFO] Max num steps: 194, rb length 9100\n",
      "2025-09-26 12:00:26,712 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:26,715 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:26,719 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:26,721 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:26,726 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:26,729 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:26,731 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:26,734 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:26,737 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:26,741 [torchrl][INFO] Max num steps: 202, rb length 10100\n",
      "2025-09-26 12:00:27,386 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:27,389 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:27,405 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:27,408 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:27,411 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:27,416 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:27,418 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:27,424 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:27,427 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:27,429 [torchrl][INFO] Max num steps: 202, rb length 11100\n",
      "2025-09-26 12:00:28,122 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,135 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,138 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,140 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,143 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,145 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,148 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,150 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,153 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,155 [torchrl][INFO] Max num steps: 202, rb length 12100\n",
      "2025-09-26 12:00:28,735 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:28,738 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:28,740 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:28,742 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:28,745 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:28,747 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:28,750 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:28,752 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:28,755 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:28,757 [torchrl][INFO] Max num steps: 202, rb length 13100\n",
      "2025-09-26 12:00:29,375 [torchrl][INFO] solved after 90000 steps, 1780 episodes and in 7.957655191421509s.\n"
     ]
    }
   ],
   "source": [
    "# train until reaching 200 steps in the environment\n",
    "\n",
    "total_count = 0\n",
    "total_episodes = 0\n",
    "t0 = time.time()\n",
    "\n",
    "for i, data in enumerate(collector):\n",
    "    rb.extend(data)\n",
    "    max_length = rb[:][\"next\", \"step_count\"].max()\n",
    "    if len(rb) > init_rand_steps:\n",
    "        for _ in range(optim_steps):\n",
    "            sample = rb.sample(128)\n",
    "            loss_vals = loss(sample)\n",
    "            loss_vals[\"loss\"].backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "            exploration_module.step(data.numel())\n",
    "\n",
    "            updater.step()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                torchrl_logger.info(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n",
    "            \n",
    "            total_count += data.numel()\n",
    "            total_episodes += data[\"next\", \"done\"].sum()\n",
    "    if max_length > 250:\n",
    "        break\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "torchrl_logger.info(\n",
    "    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a4932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-hedging3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
